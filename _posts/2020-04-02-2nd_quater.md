---
layout: post
title: "2020_2nd_quater"
date: 2020-04-02
image_url: https://user-images.githubusercontent.com/26036843/90855226-09705380-e3ba-11ea-84d8-541346225ae1.png
content: Relational inductive biases, deep learning, and graph networks
mathjax: true
comments: true
---

# Relational inductive biases, deep learning, and graph networks
## Peter W. Battaglia et al., arxiv.1806
### 발표자: 주동욱 [[Paper link](https://arxiv.org/abs/1806.01261), [Presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5e7afdd69b249c366fb7ebcd/e740fd68ab5f5f416f1de79a33a28ae5/Relational_inductive_biases%2C_deep_learning%2C_and_grpha_networks.pdf)]
- 최근 큰 관심을 받고 있는 graph neural network (GNN)의 발전 과정을 전반적으로 분석하고, 이들을 특정 기준에 따라 분류 및 향후 발전 가능성에 대해 다룬 survey 논문입니다.
- 이 논문에서는 현재 deep learning 연구 추세는 사용자의 직관을 최대한 배제하며, 소위 end-to-end learning을 지향하고 있지만, 다양한 방식으로 inductive bias를 가하고 있다고 말하고 있습니다.
- Inductive bias 중 각 data간의 relation을 보는 relation inductive bias에 의해 neural network의 component가 data를 분석하는 방식이 결정된다고 할 수 있으며, 이 중 GNN은 arbitrary relation을 분석하기 때문에
structed data를 분석하기 효과적이라고 주장합니다.
- Structured data는 사용자의 지식에 기반하여 정해지기 때문에 이를 효과적으로 활용할 경우 nurture와 nature information이 jointly 학습되어 더 효과적으로 data를 파악할 수 있다고 주장합니다.
<p align="center">
     <img src="https://user-images.githubusercontent.com/26036843/90845239-a1614380-e3a0-11ea-8b7f-11bc82530649.png">
</p>

# Item2vec: neural item embedding for collaborative filtering
## Oren Barkan and Noam Koenigstein, MLSP2016
### 발표자: 성시백 [[paper link](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5e85c9c0f2be802cc90b2504/78dd41ead9b3ae5a53732c7cea764447/item2vec.pdf), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5e85c9c0f2be802cc90b2504/74a6bbacd76accc79d96539dce59cd0b/Item2Vec.pdf)]
- Item2vec의 목적은 단어와 그 단어가 포함된 문장 사이의 관계를 분석하여 words representation을 찾는 것입니다.
- 이 목적을 달성하기 위해 Skip-Gram과  Negative sampling이라는 방법을 도입하여 성능 향상을 향상시켰으며, 이 때 사용된 skip-gram의 경우 한 sequence내의 모든 item을 탐색한다는 것에서 차별점이 있습니다.
- 제안 알고리즘을 통해 아래 그림과 같이 더 효과적으로 item vector를 embedding하여 높은 classification 성능을 보일 수 있었습니다.
<p align="center">
     <img src="https://user-images.githubusercontent.com/26036843/90846535-5694fb00-e3a3-11ea-9423-6314b1b68697.png">
</p>

# Search to Distill: Pearls are Every where but not the Eyes
## Yu Liu, Xuhui Jia, Mingxing Tan, Raviteja Vemulapalli, Yukun Zhu, Bradley Green, Xiaogang Wang, CVPR2020 (oral)
### 발표자: 이승현 [[paper link](https://arxiv.org/abs/1911.09074v2), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5e744644e4dedd86aba47d16/701406e8fb7c3c7d560d3ddf83b81a33/Search2Distill.pptx.pdf)]
- 이 논문은 knowledge distillation과 neural architecture search (NAS)를 결합한 기법으로, 각 teacher network마다 그 knowledge를 전달받기 위한 최적의 student network가 있다는 가정에서 시작합니다.
- 저자들을 이를 실험적으로 확인하기 위해 기존 NAS기법인 MNAS를 기반으로 agent에 teacher knowledge에 기반한 reward를 주어 최적의 student network를 찾도록 했습니다.
- 실험 결과 저자들의 가정과 같이 각 teacher network에 따라 다른 student network가 학습되었으며, 이들은 단일 성능 보다는 teacher network의 knowledge와 같이 학습했을 때 시너지가 난다는 것을 확인했습니다.
- 또한 knowledge를 받을 때와 그렇지 않았을 때 searching space에서 network의 각 generation을 확인한 결과 상이한 진화 방향을 가지는 것을 확인했습니다.
- 이 논문에서 제안한 새로운 NAS 방법은 높은 성능을 보인다는 점에서 큰 장점이 있지만 이미 막대한 학습비용을 사용하는 MNAS에 비해 더 많은 비용이 필요하기 때문에 일반 연구실이나 기업 수준에서는 학습하기 불가능하다는 점이 큰 단점입니다.
<p align="center">
    <img src="https://user-images.githubusercontent.com/26036843/90847181-edae8280-e3a4-11ea-8310-26cbe969b80f.png" width="500">
    <img src="https://user-images.githubusercontent.com/26036843/90847090-b0e28b80-e3a4-11ea-8516-50bebb53bb88.png" width="500">
</p>

# SpeechBERT: Cross-Modal Pre-trained Language Model for End-to-end Spoken Question Answering
## Yung-Sung Chuang Chi-Liang Liu Hung-Yi Lee, Interspeech 2020
### 발표자: 김성빈 [[paper link](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5e96ba1c3812b3075ba6bcb1/e02c2992f7179a3524f6a02463961b42/1910.11559.pdf), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5e96ba1c3812b3075ba6bcb1/a9ce0c91848879d3293bcabb18b7612e/speechbert.pdf)]
- 기존 spoken language understanding (SLU) task에서 음성인식과 자연어처리를 각각 수행하는 것과 달리, SpeachBERT에서는 이들을 end-to-end learning하여 각 part를 거치면서 누적되는 error를 최소화하는 방법을 제시했습니다.
- 이를 위해 text corpus와 speech audiio 모두에서 유의미한 semantic feature를 얻기 위한 학습방법을 제안하여 speaechBERT는 pretraining한 후 machine comprehension에 맞게 fine-tuning했습니다.
- 실험 결과에서 speechBERT는 높은 word error rate (WER)에서도 비교 기법들에 비해 높은 성능을 보였습니다.
<p align="center">
    <img src="https://user-images.githubusercontent.com/26036843/90850041-aaa3dd80-e3ab-11ea-88fb-cafc6b748ae7.png">
</p>

# MoCo v1 : Momentum Contrast for Unsupervised Visual Representation Learning
## Kaiming He Haoqi Fan Yuxin Wu Saining Xie Ross Girshick, CVPR 2020
### 발표자: 조성만 [[paper link](https://arxiv.org/abs/1911.05722), [presentation material](https://docs.google.com/presentation/d/12si9via-D6-ub98ly9P_l23aN0eqMxrCT1fMp6_84sc/edit#slide=id.p)]
- Contrastive learning 기법으로 queue와 moving-averaged encoder로 구성된 dynamic dictionary를 구성하여, 일반적인 방법으로 ImageNet을 학습한 결과와 유사한 성능을 보였습니다.
- 저자들은 Large dynamic dictionary는 EMA로 update되는 reliable한 key를 통해 negative samples를 효과적으로 제공하여 성능을 향상시킬 수 있다고 주장합니다.
- 실험결과 Mocov1으로 pretrained network는 classification 뿐만 아니라 detection task에서도 높은 성능을 보여 다양한 task에 적용가능하다는 것을 보였습니다.
<p align="center">
    <img src="https://user-images.githubusercontent.com/26036843/90855226-09705380-e3ba-11ea-84d8-541346225ae1.png">
</p>

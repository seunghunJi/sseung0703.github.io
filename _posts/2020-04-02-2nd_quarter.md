---
layout: post
title: "2020_2nd_quarter"
date: 2020-04-02
image_url: https://user-images.githubusercontent.com/26036843/91986501-b7d7a980-ed67-11ea-80b0-0d2895b08281.png
mathjax: true
comments: true
---

# Relational inductive biases, deep learning, and graph networks
## Peter W. Battaglia et al., arxiv.1806
### 발표자: 주동욱 [[Paper link](https://arxiv.org/abs/1806.01261), [Presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5e7afdd69b249c366fb7ebcd/e740fd68ab5f5f416f1de79a33a28ae5/Relational_inductive_biases%2C_deep_learning%2C_and_grpha_networks.pdf)]
- 최근 큰 관심을 받고 있는 graph neural network (GNN)의 발전 과정을 전반적으로 분석하고, 이들을 특정 기준에 따라 분류 및 향후 발전 가능성에 대해 다룬 survey 논문입니다.
- 이 논문에서는 현재 deep learning 연구 추세는 사용자의 직관을 최대한 배제하며, 소위 end-to-end learning을 지향하고 있지만, 다양한 방식으로 inductive bias를 가하고 있다고 말하고 있습니다.
- Inductive bias 중 각 data간의 relation을 보는 relation inductive bias에 의해 neural network의 component가 data를 분석하는 방식이 결정된다고 할 수 있으며, 이 중 GNN은 arbitrary relation을 분석하기 때문에
structed data를 분석하기 효과적이라고 주장합니다.
- Structured data는 사용자의 지식에 기반하여 정해지기 때문에 이를 효과적으로 활용할 경우 nurture와 nature information이 jointly 학습되어 더 효과적으로 data를 파악할 수 있다고 주장합니다.
<p align="center">
     <img src="https://user-images.githubusercontent.com/26036843/90845239-a1614380-e3a0-11ea-8b7f-11bc82530649.png">
</p>

# Item2vec: neural item embedding for collaborative filtering
## Oren Barkan and Noam Koenigstein, *MLSP2016*
### 발표자: 성시백 [[paper link](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5e85c9c0f2be802cc90b2504/78dd41ead9b3ae5a53732c7cea764447/item2vec.pdf), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5e85c9c0f2be802cc90b2504/74a6bbacd76accc79d96539dce59cd0b/Item2Vec.pdf)]
- Item2vec의 목적은 단어와 그 단어가 포함된 문장 사이의 관계를 분석하여 words representation을 찾는 것입니다.
- 이 목적을 달성하기 위해 Skip-Gram과  Negative sampling이라는 방법을 도입하여 성능 향상을 향상시켰으며, 이 때 사용된 skip-gram의 경우 한 sequence내의 모든 item을 탐색한다는 것에서 차별점이 있습니다.
- 제안 알고리즘을 통해 아래 그림과 같이 더 효과적으로 item vector를 embedding하여 높은 classification 성능을 보일 수 있었습니다.
<p align="center">
     <img src="https://user-images.githubusercontent.com/26036843/90846535-5694fb00-e3a3-11ea-9423-6314b1b68697.png">
</p>

# Search to Distill: Pearls are Every where but not the Eyes
## Yu Liu, Xuhui Jia, Mingxing Tan, Raviteja Vemulapalli, Yukun Zhu, Bradley Green, Xiaogang Wang, *CVPR2020 (oral)*
### 발표자: 이승현 [[paper link](https://arxiv.org/abs/1911.09074v2), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5e744644e4dedd86aba47d16/701406e8fb7c3c7d560d3ddf83b81a33/Search2Distill.pptx.pdf)]
- 이 논문은 knowledge distillation과 neural architecture search (NAS)를 결합한 기법으로, 각 teacher network마다 그 knowledge를 전달받기 위한 최적의 student network가 있다는 가정에서 시작합니다.
- 저자들을 이를 실험적으로 확인하기 위해 기존 NAS기법인 MNAS를 기반으로 agent에 teacher knowledge에 기반한 reward를 주어 최적의 student network를 찾도록 했습니다.
- 실험 결과 저자들의 가정과 같이 각 teacher network에 따라 다른 student network가 학습되었으며, 이들은 단일 성능 보다는 teacher network의 knowledge와 같이 학습했을 때 시너지가 난다는 것을 확인했습니다.
- 또한 knowledge를 받을 때와 그렇지 않았을 때 searching space에서 network의 각 generation을 확인한 결과 상이한 진화 방향을 가지는 것을 확인했습니다.
- 이 논문에서 제안한 새로운 NAS 방법은 높은 성능을 보인다는 점에서 큰 장점이 있지만 이미 막대한 학습비용을 사용하는 MNAS에 비해 더 많은 비용이 필요하기 때문에 일반 연구실이나 기업 수준에서는 학습하기 불가능하다는 점이 큰 단점입니다.
<p align="center">
    <img src="https://user-images.githubusercontent.com/26036843/90847181-edae8280-e3a4-11ea-8310-26cbe969b80f.png" width="450">
    <img src="https://user-images.githubusercontent.com/26036843/90847090-b0e28b80-e3a4-11ea-8516-50bebb53bb88.png" width="450">
</p>

# SpeechBERT: Cross-Modal Pre-trained Language Model for End-to-end Spoken Question Answering
## Yung-Sung Chuang, Chi-Liang Liu, Hung-Yi Lee, *Interspeech 2020*
### 발표자: 김성빈 [[paper link](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5e96ba1c3812b3075ba6bcb1/e02c2992f7179a3524f6a02463961b42/1910.11559.pdf), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5e96ba1c3812b3075ba6bcb1/a9ce0c91848879d3293bcabb18b7612e/speechbert.pdf)]
- 기존 spoken language understanding (SLU) task에서 음성인식과 자연어처리를 각각 수행하는 것과 달리, SpeachBERT에서는 이들을 end-to-end learning하여 각 part를 거치면서 누적되는 error를 최소화하는 방법을 제시했습니다.
- 이를 위해 text corpus와 speech audiio 모두에서 유의미한 semantic feature를 얻기 위한 학습방법을 제안하여 speaechBERT는 pretraining한 후 machine comprehension에 맞게 fine-tuning했습니다.
- 실험 결과에서 speechBERT는 높은 word error rate (WER)에서도 비교 기법들에 비해 높은 성능을 보였습니다.
<p align="center">
    <img src="https://user-images.githubusercontent.com/26036843/90850041-aaa3dd80-e3ab-11ea-88fb-cafc6b748ae7.png">
</p>

# Mastering the Game of Go with Deep Neural Networks and Tree Search
## David Silver1 et al., *Nature*
### 발표자: 서승현 [[paper link](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5eb93d8fb2137b5caee6b066/11c355158ddba9d2dbdc737042812b85/AlphaGoNaturePaper.pdf), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5eb93d8fb2137b5caee6b066/a9f524f884a5e11ee0ebe3c87612ac57/Alphago_SeungyhunSEO_200514__.pdf)]
- AlphaGo는 deep learning과 tree search를 결합한 알고리즘으로 이를 통해 바둑 알고리즘의 경량화 측면에서 핵심인 탐색 너비와 깊이를 줄일 수 있었습니다.
- 탐색의 너비의 경우 프로 바둑 기사의 기보를 통해 supervised learning한 network와 이를 이기기 위해 강화학습으로 학습한 policy network를 통해 줄일 수 있었습니다.
- 탐색의 깊이의 경우 value ntwork를 통해 형세를 예측하여 승패를 더 빠르게 예측할 수 있게 만들어 줄일 수 있었습니다.
- 전체적인 과성은 Monte Carlo tree search (MCTS)를 통해 병렬화 및 가속화했으며, 이를 통해 더 많은 search를 하여 높은 승률을 달성했습니다.
<p align="center">
    <img src="https://user-images.githubusercontent.com/26036843/91986501-b7d7a980-ed67-11ea-80b0-0d2895b08281.png">
</p>

# Revisiting Self-Supervised Visual Representation Learning
## Alexander Kolesnikov, Xiaohua Zhai, Lucas Beyer *CVPR2019*
### 발표자: 김민재 [[paper link](https://arxiv.org/pdf/1901.09005.pdf), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5ec263f2234a576e87a5a12e/89b02010d306066624df11aa67fc1c3f/revisiting-self-supervised-visual-representation-learning.pdf)]

# AutoML-Zero: Evolving Machine Learning Algorithms From Scratch
## Esteban Real, Chen Liang, David R. So, Quoc V. Le *CVPR2019*
### 발표자: 강진구 [[paper link](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5ea6f93c6e3f314dc61c1463/7940ecfa94e8cf9fd02885440472471f/AutoML_Zero_paper.pdf), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5ea6f93c6e3f314dc61c1463/6e72915140a1688f5d43312a7f5d866a/AutoML_Zero_presentation.pdf)]

# Mastering the Game of Go without Human Knowledge
## David Silver et al. *Nature*
### 발표자: 정승환 [[paper link](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5ec67ae26e7b2f2a913d7ccf/8445447ef143780362a6a8e66445ffc5/AlphagoZero.pdf), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5ec67ae26e7b2f2a913d7ccf/633493a7fd855c93acaf9634c392b6b1/AlphaGo_Zero!.pptx)]

# AutoSlim: Towards One-Shot Architecture Search for Channel Numbers
## Jiahui Yu, Thomas Huang *arxiv.19.03*
### 발표자: 이승현 [[paper link](https://arxiv.org/abs/1903.11728), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5ec680709116726372fa7175/0b01d34a0a1df6464284835c454578ab/Autoslim.pdf)]

# AutoSlim: Towards One-Shot Architecture Search for Channel Numbers
### 발표자: 성시백 [[paper link](https://trello.com/c/RqbXXFG1/95-object-detection), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5edf354d8121678259ae07be/7115a2e06596c5226747647c0a9e916b/keynote_OD_compressed.pdf)]

# Towards Deep Symbolic Reinforcement Learning
## Marta Garnelo, Kai Arulkumaran, Murray Shanahan *arxiv.16.09*
### 발표자: 주동욱 [[paper link](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5ee218d0f9e77b2402421396/7bae3b4c0a1e6a2c886dbb804ea3bf42/Towards_Deep_Symbolic_Reinforcement_Learning.pdf), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5ee218d0f9e77b2402421396/285af4fa5deb0c77e1d5e48f4457048b/Towrads_Deep_Symbolic_Reinforcement_Learning_duju.pdf)]







---
layout: post
title: "2020_3rd_quarter"
date: 2020-07-02
image_url: https://user-images.githubusercontent.com/32321592/91457593-79517300-e8bf-11ea-865b-57d44c1464ac.PNG
mathjax: true
comments: true
---

# Gate Decorator: Global Filter Pruning Method for Accelerating Deep Convolutional Neural Networks
## Zhonghui You, Kun Yan, Jinmian Ye, Meng Ma, Ping Wang, NeurIPS 2019
### 발표자: 이승현 [[paper link](https://arxiv.org/abs/1909.08174), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5f3a18b1378bf75d14551518/d9d8f8016b1e58e1877fc6a43b1cd812/GDP.pdf)]
- Filter pruning 기법 중 하나로 기존 기법에 비해 효과적으로 filter의 importance를 정의하고, 이를 기반으로 filter를 제거 및 pruned network를 tuning할 수 있는 방법을 제안한 논문입니다.
- Gate decorator란 Taylor expansion에 기반한 기법으로, pruning할 각 layer에 gate vector를 추가 및 이의 gradient에 기반한 score를 정하며 이는 아래와 같습니다.

$$\Theta(\phi_i) = \sum_{(X, Y) \in \mathcal D}\left| \frac{\delta \mathcal{L}(X,Y;\theta)}{\delta \phi_i} \phi_i \right| $$

- Tick step에서는 gate를 tuning 및 일정 비율을 pruning하며, Tock step에서는 손실된 성능을 복원하기 위해 일정 epoch만큼 fine-tuning 합니다. 이 때 Tock step에서는 gate에 $$L_1$$-regularization을 가해 sparce해지도록 만듭니다.
- Pruning 시에 network의 특성에 따라 서로 종속적인 layer들을 group으로 묶어 하나의 gate를 통해 importance score를 계산 및 동시에 pruning되도록 합니다.
- 높은 성능을 보이며 몇 가지 중요한 insight를 주는 좋은 기법으로 보이지만, pruning 시간이 매우 길다는 것은 큰 단점으로 보입니다.

<p align="center">
  <img src="https://user-images.githubusercontent.com/26036843/90788752-14d36880-e341-11ea-829e-2485ce943e91.png">
  <img src="https://user-images.githubusercontent.com/26036843/90788498-d63dae00-e340-11ea-87b5-7a0f37c1d93a.png">
</p>


# Data-Efficient Hierarchical Reinforcement Learning (HIRO)
## Ofir Nachum, Shixiang Gu, Honglak Lee, Sergey Levine
### 발표자: 주동욱 [[paper link](https://arxiv.org/abs/1805.08296), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5f433e7cd7804e0c251f6146/0f5d11f0886ebead360e5b1119f652ea/HIRO_%EC%A3%BC%EB%8F%99%EC%9A%B1.pdf)]
- Task Hierarchy가 복잡한 Continuous Action Space 환경에서 Generally Applicable Off-Policy HRL 알고리즘을 제안하였습니다.
- 기존의 HRL은 higher-level policy를 최적화하는 과정에서 non-stationary problem으로 인하여 On-Policy 방식으로 업데이트를 하여 Sample Efficiency가 떨어지는 단점이 있었지만, 본 논문에서는 Off-Policy Correction을 통하여 이를 해결한 Off-Policy 알고리즘을 제안하였습니다.
- 단점으로는 HRL 이 모두 그렇지만 Task 의 Hierarchical Structure 가 명확하지 않을 때는 쓰기 어렵습니다. 반대로 Locomotive Task 계열에서는 자연스럽게 적용 가능할 것으로 보입니다.
- General HRL Algorithm 중에서 비교적 초기의(2018) 논문이므로 이어질 이후 이어지는 연구 동향을 살펴보면 좋을 것 같습니다.

<p align="center">
  <img src="https://user-images.githubusercontent.com/32321592/91457593-79517300-e8bf-11ea-865b-57d44c1464ac.PNG">
  <img src="https://user-images.githubusercontent.com/32321592/91457597-7a82a000-e8bf-11ea-9d1c-aabe88d567ad.PNG">
</p>


# wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations
## Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli
### 발표자: 김성빈 [[paper link](https://arxiv.org/pdf/2006.11477.pdf), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5f1aad71ab3a130c1e0525f1/af29044c08c46289dc504ada199cebe5/wav2vec2_presentation_%EC%88%98%EC%A0%95.pdf)]
- 비교적 구하기 쉬운 Unlabeled 음성데이터를 통해 General한 Representation을 배우는 Self-Supervised 기법을 제시
- 10분의 labeled 음성만으로도 사용 가능한 수준의 성능을 지닌 음성인식모델을 학습할 수 있음
- 비슷한 방법으로 기존에 vq-wav2vec이 존재했지만 Quantization을 한 후에 Bert학습을 하는 two-step으로 구성되어있고 Qunatization을 하면서 정보가 손실되는 단점이 있었음
- wav2vec2.0은 Continuos한 input으로 학습을 하고 two-step을 End-to-End로 학습 할 수 있는 방법을 제시함으로서 성능을 개선하였음
- 데이터셋이 거의 없는 언어에 대해서도 음성인식모델 구축을 가능하게 할 수 있는 가능성을 제시함으로써 Self-supervised 음성인식에 크게 의미있는 연구라고 생각됨
<p align="center">
  <img src="https://user-images.githubusercontent.com/25909311/92239225-9b697780-eef5-11ea-8cab-60c9ec24ca90.png">
</p>

# FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence
## Kihyuk Sohn, David Berthelot, Chun-Liang Li, Zizhao Zhang, Nicholas Carlini, Ekin D. Cubuk, Alex Kurakin, Han Zhang, Colin Raffel
### 발표자: 강진구 [[paper link](https://arxiv.org/pdf/2001.07685.pdf), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5f539ebd49daad7017f78901/4b070d570064ba036deccdf816f1e7aa/FixMatch.pdf)]
- Semi-Supervised Learning 연구에서 대표적인 두 가지 방법인 Consistency Regularization (CR)과 Pseudo Labeling  (PL)을 잘 조합하여 간단한 방법으로 좋은 성능을 보였습니다.
- Data Augmentation (DA)을 적절히 사용하는 것이 핵심인데, PL을 위한 모델에 데이터에는 약한 DA를, CR을 위한 모델의 데이터에는 강한 DA를 적용했습니다.
- 프로세스는 두 단계로 다음과 같습니다. (이하 데이터는 unlabeled data 입니다. labeled data는 기존 방식대로 트레이닝합니다.)
    1. 약한 DA를 가한 데이터가 모델에 입력되어 각 클래스에 대한 분포가 출력되었을 때 어떤 하나의 클래스의 분포 값이 정해둔 threshold보다 크다면 그 클래스를 label로 가정합니다. (PL)  
    2. 강한 DA를 가한 데이터를 모델에 입력하고 1단계에서 준비해둔 pseudo label을 label로 간주하여 트레이닝합니다. (CR)

<p align="center">
<img src="https://user-images.githubusercontent.com/25892000/92998914-d1db6e00-f557-11ea-8147-b518f18debe1.png">
</p>


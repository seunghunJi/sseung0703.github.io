---
layout: post
title: "2020_3rd_quarter"
date: 2020-07-02
image_url: https://user-images.githubusercontent.com/32321592/91457593-79517300-e8bf-11ea-865b-57d44c1464ac.PNG
mathjax: true
comments: true
---

# Unsupervised Cross-Modal Alignment of Speech and Text Embedding Spaces
## Yu-An Chung, Wei-Hung Weng, Schrasing Tong, James Glass
### 발표자: 강진구 [[paper link](https://arxiv.org/pdf/1805.07467.pdf), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5f02bdd4b0d4f0561a33f47e/d3d19109ef206fd6ea1c4537529531ce/Unsupervised_Cross-Modal_Alignment_of_Speech_and_Text_Embedding_Spaces.pdf)]
- 음성에서 직접 word embedding을 추출하는 speech2vec의 후속 논문입니다.
- speech2vec에서는 음성을 forced alignment라는 방법으로 text와의 align을 맞추어서 그 alignment에 따라 단어들의 구간을 구분하고 구분된 단어 음성들을 가지고 skipgrams와 cbow 방법을 이용하여 word embedding을 추출합니다. 그런데 forced alignment는 음성에 해당하는 텍스트를 필요로 하는 방법이기 때문에 fully unsupervised라고 볼 수 없습니다.
- 본 논문에서는 여러 clustering algorithm (BES-GMM, Embedded segmental K-means, Recurring syllable-unit segmenter) 를 이용하여 speech2vec을 fully unsupervised 하게 발전 시켰습니다.
- 음성을 텍스트처럼 의미단위로 discrete하게 만들어 보려고 시도하는 참신한 연구라고 생각합니다.
<p align="center">
<img src="https://user-images.githubusercontent.com/25892000/92999642-8deb6780-f55d-11ea-8acc-2c483433f588.png">
</p>

***

# Learning Imbalanced Datasets with Label-Distribution-Aware Margin Loss
## Kaidi Cao et al. NIPS (2019)
### 발표자: 서승현 [[paper link](http://papers.nips.cc/paper/8435-learning-imbalanced-datasets-with-label-distribution-aware-margin-loss.pdf), [presentation material](https://drive.google.com/file/d/189yFTCT8AXHd6QNDvvcK7Umngv-MEoy-/view)]
- 일반적으로 딥러닝 연구,프로젝트에 존재하는 데이터의 불균형 문제를 머신러닝 기법 관점에서 해결한 논문입니다.
- 기존의 Cross-Entropy와 Large Margin loss 를 기반으로 label class distribution 에 dependent한 Label-Distribution-Aware Margin Loss (이하 LDAM loss) 를 수학적으로 증명하여 적용하였습니다.
- 추가적으로 Deferred Re-Weighting(DRW) 기법을 통해서 충분히 학습이 진행되고 난 뒤에 re-weighting을 하는것이 여러가지 Computer Vision 태스크에 있어서 LDAM과 결합 했을 때 좋은 성능을 보임을 입증하였습니다.


<p align="center">
  <img src="https://user-images.githubusercontent.com/48202736/93779026-77ca5f00-fc61-11ea-972b-703bdba5c6b8.jpg">
  <img src="https://user-images.githubusercontent.com/48202736/93779031-79942280-fc61-11ea-86cc-1e1c3e08342f.jpg">
  <img src="https://user-images.githubusercontent.com/48202736/93779039-7b5de600-fc61-11ea-91d3-10805a9fe206.jpg">
</p>

***

# Gate Decorator: Global Filter Pruning Method for Accelerating Deep Convolutional Neural Networks
## Zhonghui You, Kun Yan, Jinmian Ye, Meng Ma, Ping Wang, NeurIPS 2019
### 발표자: 이승현 [[paper link](https://arxiv.org/abs/1909.08174), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5f3a18b1378bf75d14551518/d9d8f8016b1e58e1877fc6a43b1cd812/GDP.pdf)]
- Filter pruning 기법 중 하나로 기존 기법에 비해 효과적으로 filter의 importance를 정의하고, 이를 기반으로 filter를 제거 및 pruned network를 tuning할 수 있는 방법을 제안한 논문입니다.
- Gate decorator란 Taylor expansion에 기반한 기법으로, pruning할 각 layer에 gate vector를 추가 및 이의 gradient에 기반한 score를 정하며 이는 아래와 같습니다.

$$\Theta(\phi_i) = \sum_{(X, Y) \in \mathcal D}\left| \frac{\delta \mathcal{L}(X,Y;\theta)}{\delta \phi_i} \phi_i \right| $$

- Tick step에서는 gate를 tuning 및 일정 비율을 pruning하며, Tock step에서는 손실된 성능을 복원하기 위해 일정 epoch만큼 fine-tuning 합니다. 이 때 Tock step에서는 gate에 $$L_1$$-regularization을 가해 sparce해지도록 만듭니다.
- Pruning 시에 network의 특성에 따라 서로 종속적인 layer들을 group으로 묶어 하나의 gate를 통해 importance score를 계산 및 동시에 pruning되도록 합니다.
- 높은 성능을 보이며 몇 가지 중요한 insight를 주는 좋은 기법으로 보이지만, pruning 시간이 매우 길다는 것은 큰 단점으로 보입니다.

<p align="center">
  <img src="https://user-images.githubusercontent.com/26036843/90788752-14d36880-e341-11ea-829e-2485ce943e91.png">
  <img src="https://user-images.githubusercontent.com/26036843/90788498-d63dae00-e340-11ea-87b5-7a0f37c1d93a.png">
</p>

***

# Data-Efficient Hierarchical Reinforcement Learning (HIRO)
## Ofir Nachum, Shixiang Gu, Honglak Lee, Sergey Levine
### 발표자: 주동욱 [[paper link](https://arxiv.org/abs/1805.08296), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5f433e7cd7804e0c251f6146/0f5d11f0886ebead360e5b1119f652ea/HIRO_%EC%A3%BC%EB%8F%99%EC%9A%B1.pdf)]
- Task Hierarchy가 복잡한 Continuous Action Space 환경에서 Generally Applicable Off-Policy HRL 알고리즘을 제안하였습니다.
- 기존의 HRL은 higher-level policy를 최적화하는 과정에서 non-stationary problem으로 인하여 On-Policy 방식으로 업데이트를 하여 Sample Efficiency가 떨어지는 단점이 있었지만, 본 논문에서는 Off-Policy Correction을 통하여 이를 해결한 Off-Policy 알고리즘을 제안하였습니다.
- 단점으로는 HRL 이 모두 그렇지만 Task 의 Hierarchical Structure 가 명확하지 않을 때는 쓰기 어렵습니다. 반대로 Locomotive Task 계열에서는 자연스럽게 적용 가능할 것으로 보입니다.
- General HRL Algorithm 중에서 비교적 초기의(2018) 논문이므로 이어질 이후 이어지는 연구 동향을 살펴보면 좋을 것 같습니다.

<p align="center">
  <img src="https://user-images.githubusercontent.com/32321592/91457593-79517300-e8bf-11ea-865b-57d44c1464ac.PNG">
  <img src="https://user-images.githubusercontent.com/32321592/91457597-7a82a000-e8bf-11ea-9d1c-aabe88d567ad.PNG">
</p>

***

# wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations
## Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli
### 발표자: 김성빈 [[paper link](https://arxiv.org/pdf/2006.11477.pdf), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5f1aad71ab3a130c1e0525f1/af29044c08c46289dc504ada199cebe5/wav2vec2_presentation_%EC%88%98%EC%A0%95.pdf)]
- 비교적 구하기 쉬운 Unlabeled 음성데이터를 통해 General한 Representation을 배우는 Self-Supervised 기법을 제시
- 10분의 labeled 음성만으로도 사용 가능한 수준의 성능을 지닌 음성인식모델을 학습할 수 있음
- 비슷한 방법으로 기존에 vq-wav2vec이 존재했지만 Quantization을 한 후에 Bert학습을 하는 two-step으로 구성되어있고 Qunatization을 하면서 정보가 손실되는 단점이 있었음
- wav2vec2.0은 Continuos한 input으로 학습을 하고 two-step을 End-to-End로 학습 할 수 있는 방법을 제시함으로서 성능을 개선하였음
- 데이터셋이 거의 없는 언어에 대해서도 음성인식모델 구축을 가능하게 할 수 있는 가능성을 제시함으로써 Self-supervised 음성인식에 크게 의미있는 연구라고 생각됨
<p align="center">
  <img src="https://user-images.githubusercontent.com/25909311/92239225-9b697780-eef5-11ea-8cab-60c9ec24ca90.png">
</p>

# FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence
## Kihyuk Sohn, David Berthelot, Chun-Liang Li, Zizhao Zhang, Nicholas Carlini, Ekin D. Cubuk, Alex Kurakin, Han Zhang, Colin Raffel
### 발표자: 강진구 [[paper link](https://arxiv.org/pdf/2001.07685.pdf), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5f539ebd49daad7017f78901/4b070d570064ba036deccdf816f1e7aa/FixMatch.pdf)]
- Semi-Supervised Learning 연구에서 대표적인 두 가지 방법인 Consistency Regularization (CR)과 Pseudo Labeling  (PL)을 잘 조합하여 간단한 방법으로 좋은 성능을 보였습니다.
- Data Augmentation (DA)을 적절히 사용하는 것이 핵심인데, PL을 위한 모델에 데이터에는 약한 DA를, CR을 위한 모델의 데이터에는 강한 DA를 적용했습니다.
- 프로세스는 두 단계로 다음과 같습니다. (이하 데이터는 unlabeled data 입니다. labeled data는 기존 방식대로 트레이닝합니다.)
    1. 약한 DA를 가한 데이터가 모델에 입력되어 각 클래스에 대한 분포가 출력되었을 때 어떤 하나의 클래스의 분포 값이 정해둔 threshold보다 크다면 그 클래스를 label로 가정합니다. (PL)  
    2. 강한 DA를 가한 데이터를 모델에 입력하고 1단계에서 준비해둔 pseudo label을 label로 간주하여 트레이닝합니다. (CR)

<p align="center">
<img src="https://user-images.githubusercontent.com/25892000/92998914-d1db6e00-f557-11ea-8147-b518f18debe1.png">
</p>

***

# Language Models are Few-Shot Learners
## Tom B. Brown et al. 2020
### 발표자: 서승현 [[paper link](https://arxiv.org/pdf/2005.14165), [presentation material](???)]
- 최근 딥러닝 분야, 그 중 text generation 분야에서 가장 핫한 GPT-3 에 대한 논문입니다.
- 논문의 핵심은 모델이 파인튜닝 없이, 몇 가지 예제만 주어졌을때 (이는 few-shot 이라고 하고, 아예 없는 경우 zero shot) 컨텍스트에 내재된 맥락을 파악하고 이를 통해 task specific한 질문을 받았을 때 그에 해당하는 답을 내는 것 입니다. 
- 논문에서 소개한 GPT-3 모델은 구조적으로 GPT1,2와 크게 다른 바 없는 트랜스포머의 source attention 부분이 없는 디코더 부분이며, 논문에서는 파라메터 개수와 네트워크에 주는 in context examples 수를 변수로 하여 모델 성능을 다양한 태스크에 대해서 평가하였습니다.

<p align="center">
  <img src="https://user-images.githubusercontent.com/48202736/93779192-a8aa9400-fc61-11ea-8faa-4eeeda5ba677.jpg">
  <img src="https://user-images.githubusercontent.com/48202736/93779087-903a7980-fc61-11ea-9f97-8cfb95e1562f.jpg">
</p>
